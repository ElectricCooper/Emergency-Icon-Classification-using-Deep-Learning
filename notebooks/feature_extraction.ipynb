{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad60f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c6c365",
   "metadata": {},
   "source": [
    "# geometric_features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04b06487",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeometricFeatures:\n",
    "    \"\"\"Extract geometric features from binary images\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_perimeter(image):\n",
    "        \"\"\"Calculate the perimeter of contours in a binary image\"\"\"\n",
    "        contours, _ = cv2.findContours(\n",
    "                        image,\n",
    "                        cv2.RETR_EXTERNAL,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE\n",
    "                        )\n",
    "        return sum(cv2.arcLength(cnt, True) for cnt in contours)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_area(image):\n",
    "        \"\"\"Compute area of binary image\"\"\"\n",
    "        return float(cv2.countNonZero(image))\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_compactness(perimeter, area):\n",
    "        \"\"\"Calculate compactness = (area * 4 * pi) / (perimeter^2)\"\"\"\n",
    "        if perimeter <= 0:\n",
    "            return 0.0\n",
    "        return (area * 4 * np.pi) / (perimeter ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_convex_area(image):\n",
    "        \"\"\"Calculate area using convex hull of the largest contour\"\"\"\n",
    "        contours, _ = cv2.findContours(\n",
    "                        image,\n",
    "                        cv2.RETR_EXTERNAL,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if not contours:\n",
    "            return 0.0\n",
    "\n",
    "        # Combine all contours points to handle multiple part drawings\n",
    "        all_points = np.vstack(contours)\n",
    "        hull = cv2.convexHull(all_points)\n",
    "        convex_area = cv2.contourArea(hull)\n",
    "        area = GeometricFeatures.compute_area(image)\n",
    "\n",
    "        solidity = area / convex_area if convex_area > 0 else 0\n",
    "\n",
    "        return {\"convex_area\": convex_area, \"solidity\": solidity}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad061ffc",
   "metadata": {},
   "source": [
    "# lines.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f075ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineDetection:\n",
    "    \"\"\"Detect and regroup lines in images\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_lines(image):\n",
    "        \"\"\"Detect lines using Hough Transform\"\"\"\n",
    "        # Apply Canny edge detection\n",
    "        lines = cv2.HoughLinesP(\n",
    "            image,\n",
    "            rho=1,\n",
    "            theta=np.pi/180,\n",
    "            threshold=20,      # min intersections to detect line\n",
    "            minLineLength=15,  # min length of line\n",
    "            maxLineGap=5       # max gap between pixels\n",
    "        )\n",
    "\n",
    "        if lines is None:\n",
    "            return []\n",
    "\n",
    "        raw_lines = [line[0] for line in lines]\n",
    "\n",
    "        # return list of x1,y1,x2,y2\n",
    "        return LineDetection.group_lines_with_limits(raw_lines)\n",
    "\n",
    "    @staticmethod\n",
    "    def classify_directions(lines):\n",
    "        \"\"\"Classify lines into horizontal, vertical, and diagonal\"\"\"\n",
    "        results = {'horizontal': 0, 'vertical': 0, 'diag1': 0, 'diag2': 0}\n",
    "\n",
    "        for x1, y1, x2, y2 in lines:\n",
    "            label, _ = LineDetection.get_line_info(x1, y1, x2, y2)\n",
    "            results[label] += 1\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def get_line_info(x1, y1, x2, y2):\n",
    "        \"\"\"Calculate angle and return label with color\"\"\"\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        # Calculate angle in degrees (0-180)\n",
    "        angle = np.degrees(np.arctan2(dy, dx)) % 180  # Normalize to 0-180\n",
    "\n",
    "        if angle <= 22.5 or angle >= 157.5:\n",
    "            return 'horizontal', (255, 0, 0)  # Blue\n",
    "        elif 67.5 <= angle <= 112.5:\n",
    "            return 'vertical', (0, 255, 0)  # Green\n",
    "        elif 22.5 < angle < 67.5:\n",
    "            return 'diag1', (0, 0, 255)  # Red\n",
    "        else:\n",
    "            return 'diag2', (0, 255, 255)  # Yellow\n",
    "\n",
    "    @staticmethod\n",
    "    def group_lines_with_limits(lines):\n",
    "        \"\"\"Filters lines with spatial separation and quantity limits\"\"\"\n",
    "        categories = {'horizontal': [],\n",
    "                      'vertical': [],\n",
    "                      'diag1': [],\n",
    "                      'diag2': []}\n",
    "\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            # Calculate length for sorting\n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            label, _ = LineDetection.get_line_info(x1, y1, x2, y2)\n",
    "\n",
    "            if label in categories:\n",
    "                categories[label].append((line, length))\n",
    "\n",
    "        final_lines = []\n",
    "\n",
    "        # Limit horizontal lines to 3\n",
    "        categories['horizontal'].sort(key=lambda x: x[1], reverse=True)\n",
    "        h_kept = []\n",
    "        for line, _ in categories['horizontal']:\n",
    "            if len(h_kept) < 3:\n",
    "                mid_y = (line[1] + line[3]) / 2\n",
    "                # Keep if vertical distance from others is > 10px\n",
    "                if all(abs(mid_y - ((h[1] + h[3]) / 2)) > 10 for h in h_kept):\n",
    "                    h_kept.append(line)\n",
    "\n",
    "        # Limit vertical lines to 3\n",
    "        categories['vertical'].sort(key=lambda x: x[1], reverse=True)\n",
    "        v_kept = []\n",
    "        for line, _ in categories['vertical']:\n",
    "            if len(v_kept) < 3:\n",
    "                mid_x = (line[0] + line[2]) / 2\n",
    "                # Keep if horizontal distance from others is > 10px\n",
    "                if all(abs(mid_x - ((v[0] + v[2]) / 2)) > 10 for v in v_kept):\n",
    "                    v_kept.append(line)\n",
    "\n",
    "        # Filtering diagonals too close to each other (no limits)\n",
    "        for d_type in ['diag1', 'diag2']:\n",
    "            categories[d_type].sort(key=lambda x: x[1], reverse=True)\n",
    "            d_kept = []\n",
    "\n",
    "            for line, _ in categories[d_type]:\n",
    "                # Center point\n",
    "                mid_x = (line[0] + line[2]) / 2\n",
    "                mid_y = (line[1] + line[3]) / 2\n",
    "\n",
    "                # Check distance\n",
    "                is_too_close = False\n",
    "                for k_line in d_kept:\n",
    "                    k_mid_x = (k_line[0] + k_line[2]) / 2\n",
    "                    k_mid_y = (k_line[1] + k_line[3]) / 2\n",
    "                    dist = np.sqrt((mid_x - k_mid_x)**2 + (mid_y - k_mid_y)**2)\n",
    "\n",
    "                    if dist < 5:\n",
    "                        is_too_close = True\n",
    "                        break\n",
    "\n",
    "                if not is_too_close:\n",
    "                    d_kept.append(line)\n",
    "\n",
    "        final_lines.extend(h_kept)\n",
    "        final_lines.extend(v_kept)\n",
    "        final_lines.extend(d_kept)\n",
    "\n",
    "        return final_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898e7da",
   "metadata": {},
   "source": [
    "# diagonal.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ea05d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagonalAnalysis:\n",
    "    \"\"\"Analyze diagonal properties of drawings\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_diagonal(image):\n",
    "        \"\"\"Find and measure diagonal of the drawing\"\"\"\n",
    "        # Safe checking image is 1-channel (binary from process.py)\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find coordinates of all non-zero (white) pixels\n",
    "        coords = cv2.findNonZero(image)\n",
    "\n",
    "        if coords is None:\n",
    "            return {'length': 0, 'angle': 0}\n",
    "\n",
    "        _, _, w, h = cv2.boundingRect(coords)  # Bounding box\n",
    "\n",
    "        # Calculate diagonal length and angle\n",
    "        diagonal_length = np.sqrt(w**2 + h**2)\n",
    "        diagonal_angle = np.degrees(np.arctan2(h, w))\n",
    "\n",
    "        return {\n",
    "            'length': round(diagonal_length, 3),\n",
    "            'angle': round(diagonal_angle, 3)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552da41d",
   "metadata": {},
   "source": [
    "# moments.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2a7fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentsFeatures:\n",
    "    \"\"\"Extract moment-based features\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_hu_moments(image):\n",
    "        \"\"\"Calculate Hu moments\"\"\"\n",
    "        # Calculate moments\n",
    "        moments = cv2.moments(image, True)\n",
    "        hu_moments = cv2.HuMoments(moments).flatten()\n",
    "\n",
    "        # Apply log transform to make them more manageable\n",
    "        hu_moments = -np.sign(hu_moments)*np.log10(np.abs(hu_moments)+1e-10)\n",
    "\n",
    "        return hu_moments.tolist()\n",
    "\n",
    "    @staticmethod\n",
    "    def gravity_center(image):\n",
    "        \"\"\"Calculate center of gravity\"\"\"\n",
    "        moments = cv2.moments(image, True)\n",
    "\n",
    "        if moments['m00'] == 0:\n",
    "            return (0, 0)\n",
    "\n",
    "        cx = moments['m10'] / moments['m00']\n",
    "        cy = moments['m01'] / moments['m00']\n",
    "\n",
    "        return (cx, cy)\n",
    "\n",
    "    @staticmethod\n",
    "    def average_centroidal_radius(image):\n",
    "        \"\"\"Calculate average centroidal radius\"\"\"\n",
    "        cx, cy = MomentsFeatures.gravity_center(image)\n",
    "        contours, _ = cv2.findContours(\n",
    "                        image,\n",
    "                        cv2.RETR_EXTERNAL,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE\n",
    "                        )\n",
    "\n",
    "        if not contours:\n",
    "            return 0.0\n",
    "\n",
    "        all_points = np.vstack(contours).squeeze()\n",
    "\n",
    "        # Forcing to 2D\n",
    "        if all_points.ndim == 1:  # if single point it would be 1D\n",
    "            all_points = np.array([all_points])\n",
    "\n",
    "        distances = np.sqrt(np.sum((all_points - [cx, cy])**2, axis=1))\n",
    "\n",
    "        return float(np.mean(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b8e93",
   "metadata": {},
   "source": [
    "# poi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4edbff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POIDetection:\n",
    "    \"\"\"Detect points of interest, here corners only\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_all_corners(image, epsilon_factor=0.02):\n",
    "        \"\"\"Detect corners with significant angle changes\n",
    "            by simplifying contours into polygons\n",
    "        \"\"\"\n",
    "        contours, _ = cv2.findContours(\n",
    "                        image,\n",
    "                        cv2.RETR_EXTERNAL,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE\n",
    "                    )\n",
    "\n",
    "        corner_count = 0\n",
    "        approxs = []\n",
    "        for cnt in contours:\n",
    "            # Espilon : max distance from contour to approximated shape\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "            epsilon = epsilon_factor * perimeter\n",
    "\n",
    "            # Approximate shape with a polygon\n",
    "            approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "            approxs.append(approx)\n",
    "\n",
    "            # Number of vertices in polygon is the number of corners\n",
    "            corner_count += len(approx)\n",
    "\n",
    "        return corner_count, approxs\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_sharp_corners(image,\n",
    "                             max_corners=20,\n",
    "                             quality_level=0.01,\n",
    "                             min_distance=10):\n",
    "        \"\"\"Find most sharp corners using Shi-Tomasi method\"\"\"\n",
    "        corners = cv2.goodFeaturesToTrack(\n",
    "            image,\n",
    "            maxCorners=max_corners,\n",
    "            qualityLevel=quality_level,\n",
    "            minDistance=min_distance\n",
    "        )\n",
    "        count = len(corners) if corners is not None else 0\n",
    "        return count, corners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5825129",
   "metadata": {},
   "source": [
    "# ellipse.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "195e1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EllipseDetection:\n",
    "    \"\"\"Detect ellipses in images\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_ellipses(image, min_ratio=0.3, min_area=20):\n",
    "        \"\"\"Detect ellipses in an image\"\"\"\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        # Close small gaps in circles\n",
    "        image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "        contours, _ = cv2.findContours(image, cv2.RETR_LIST,\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        detected_ellipses = []\n",
    "        for contour in contours:\n",
    "            if len(contour) < 5:\n",
    "                continue\n",
    "            area = cv2.contourArea(contour)\n",
    "            hull_area = cv2.contourArea(cv2.convexHull(contour))\n",
    "            solidity = area / hull_area if hull_area > 0 else 0\n",
    "            if solidity > 0.92 and area >= min_area:\n",
    "\n",
    "                ellipse = cv2.fitEllipse(contour)\n",
    "                # Aspect ratio\n",
    "                w, h = ellipse[1]\n",
    "                ratio = min(w, h) / max(w, h) if max(w, h) > 0 else 0\n",
    "\n",
    "                # Circularity (making sure it's not a random pt scatter)\n",
    "                perimeter = cv2.arcLength(contour, True)\n",
    "                circularity = 0\n",
    "                if perimeter > 0:\n",
    "                    circularity = (4*np.pi*area)/(perimeter**2)\n",
    "\n",
    "                if ratio > min_ratio and circularity > 0.75:  # Thresholds\n",
    "                    detected_ellipses.append(ellipse)\n",
    "\n",
    "        # Sort (descending) by area\n",
    "        detected_ellipses.sort(key=lambda e: e[1][0] * e[1][1], reverse=True)\n",
    "        # Filter overlapping ellipses and select top 2\n",
    "        # (we don't expect more than 2 ellipses in icons)\n",
    "        top_ellipses = EllipseDetection.filter_overlapping_ellipses(\n",
    "            detected_ellipses, max_out=2)\n",
    "\n",
    "        if len(top_ellipses) == 2:\n",
    "            area1 = top_ellipses[0][1][0] * top_ellipses[0][1][1]\n",
    "            area2 = top_ellipses[1][1][0] * top_ellipses[1][1][1]\n",
    "\n",
    "            # If biggest ellipse is way larger than the second,\n",
    "            # it's not wheels which is the only pair of circle acceptable\n",
    "            # So we keep only the main one.\n",
    "            if area1 > area2 * 3:\n",
    "                return [top_ellipses[0]]\n",
    "\n",
    "        return top_ellipses\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_overlapping_ellipses(ellipses, overlap_threshold=0.6,\n",
    "                                    max_out=2):\n",
    "        \"\"\"Filter overlapping ellipses, returning maximum 'max_out' results\"\"\"\n",
    "        if not ellipses:\n",
    "            return []\n",
    "\n",
    "        filtered = []\n",
    "        for candidate in ellipses:\n",
    "            if len(filtered) >= max_out:\n",
    "                break\n",
    "\n",
    "            is_overlap = False\n",
    "            c1 = candidate[0]\n",
    "            # Radius based filtering\n",
    "            r1 = max(candidate[1]) / 2\n",
    "\n",
    "            for fixed in filtered:\n",
    "                c2 = fixed[0]\n",
    "                r2 = max(fixed[1]) / 2\n",
    "\n",
    "                # distance between centers\n",
    "                dist = np.sqrt((c1[0] - c2[0])**2 + (c1[1] - c2[1])**2)\n",
    "\n",
    "                # if centers are closer than a % of the largest radius\n",
    "                if dist < max(r1, r2) * overlap_threshold:\n",
    "                    is_overlap = True\n",
    "                    break\n",
    "\n",
    "            if not is_overlap:\n",
    "                filtered.append(candidate)\n",
    "\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4ec0c",
   "metadata": {},
   "source": [
    "# subdivider.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f9bdd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSubdivision:\n",
    "    \"\"\"Subdivide images into grid cells\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def subdivide(image, rows, cols):\n",
    "        \"\"\"Divide image into rows x cols sub images\"\"\"\n",
    "        sub_image_height = image.shape[0] // rows\n",
    "        sub_image_width = image.shape[1] // cols\n",
    "\n",
    "        sub_images = []\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                x = j * sub_image_width\n",
    "                y = i * sub_image_height\n",
    "                sub_image = image[y:y + sub_image_height,\n",
    "                                  x:x + sub_image_width].copy()\n",
    "                sub_images.append(sub_image)\n",
    "\n",
    "        return sub_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1ebfb",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63c6f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IconFeatureExtractor:\n",
    "    \"\"\"Consolidated feature extraction pipeline with optimized logic\"\"\"\n",
    "\n",
    "    def __init__(self, rows=2, cols=3):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "\n",
    "    def extract_core_features(self, binary):\n",
    "        \"\"\"Helper to extract shared features for both global and sub-zones\"\"\"\n",
    "        # Lines\n",
    "        filtered_lines = LineDetection.detect_lines(binary)\n",
    "        line_directions = LineDetection.classify_directions(filtered_lines)\n",
    "\n",
    "        # POI\n",
    "        total_corners, _ = POIDetection.detect_all_corners(binary)\n",
    "        sharp_corners, _ = POIDetection.detect_sharp_corners(binary)\n",
    "\n",
    "        # Geometry & Moments\n",
    "        perimeter = GeometricFeatures.calculate_perimeter(binary)\n",
    "        area = GeometricFeatures.compute_area(binary)\n",
    "        compactness = GeometricFeatures.compute_compactness(perimeter, area)\n",
    "        hu_moments = MomentsFeatures.get_hu_moments(binary)\n",
    "\n",
    "        return {\n",
    "            'perimeter': perimeter,\n",
    "            'area': int(area),\n",
    "            'compactness': compactness,\n",
    "            'hu_moments': hu_moments,\n",
    "            'corners_count': total_corners,\n",
    "            'sharp_corners_count': sharp_corners,\n",
    "            'line_directions': line_directions\n",
    "        }\n",
    "\n",
    "    def extract_features_from_image(self, image_path):\n",
    "        \"\"\"Extract features from a single image using consolidated logic\"\"\"\n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None:\n",
    "            return None\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Subdivision features extraction\n",
    "        sub_zones = ImageSubdivision.subdivide(binary, self.rows, self.cols)\n",
    "        subdivision_features = []\n",
    "        for zone in sub_zones:\n",
    "            subdivision_features.append(self.extract_core_features(zone))\n",
    "\n",
    "        # Global features extraction\n",
    "        features = {'subdivisions': subdivision_features}\n",
    "        global_f = self.extract_core_features(binary)\n",
    "\n",
    "        # Adding global features\n",
    "        ellipses = EllipseDetection.detect_ellipses(binary)\n",
    "        diag = DiagonalAnalysis.analyze_diagonal(binary)\n",
    "        convex_area = GeometricFeatures.calculate_convex_area(binary)\n",
    "        avg_centr_radius = MomentsFeatures.average_centroidal_radius(binary)\n",
    "\n",
    "        global_f.update({\n",
    "            'ellipse_count': len(ellipses),\n",
    "            'diagonal_length': diag['length'],\n",
    "            'diagonal_angle': diag['angle'],\n",
    "            'convex_area': convex_area,\n",
    "            'avg_centroidal_radius': avg_centr_radius\n",
    "        })\n",
    "\n",
    "        features['global'] = global_f\n",
    "        return features\n",
    "\n",
    "    def process_dataset(self, data_dir, output_json='features_dataset.json'):\n",
    "        \"\"\"Walks through folders, extracts features, and save to JSON\"\"\"\n",
    "        data_dir = Path(data_dir)\n",
    "        dataset = []\n",
    "\n",
    "        if not data_dir.exists():\n",
    "            print(f\"Error: Directory {data_dir} does not exist.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Scanning directory: {data_dir}\")\n",
    "\n",
    "        for label_folder in filter(Path.is_dir, data_dir.iterdir()):\n",
    "            label = label_folder.name\n",
    "            if label in [\"duplicates\", \"detection\"]:\n",
    "                continue\n",
    "            print(f\"Processing class: {label}\")\n",
    "            \n",
    "            for img_file in label_folder.glob('*.png'):\n",
    "                feat = self.extract_features_from_image(img_file)\n",
    "                if feat:\n",
    "                    feat.update({'label': label, 'filename': img_file.name})\n",
    "                    dataset.append(feat)\n",
    "\n",
    "        # Output JSON to the Root directory (parent of notebooks)\n",
    "        # assuming the notebook is running inside /notebooks\n",
    "        output_path = Path(\"..\") / output_json\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dataset, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nSuccessfully processed {len(dataset)} images.\")\n",
    "        print(f\"Features saved to: {output_path.resolve()}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594584d2",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef8cbe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: ..\\data\\extracted\n",
      "Processing class: Bomb\n",
      "Processing class: Car\n",
      "Processing class: Casualty\n",
      "Processing class: Electricity\n",
      "Processing class: Fire\n",
      "Processing class: Fire_brigade\n",
      "Processing class: Flood\n",
      "Processing class: Gas\n",
      "Processing class: Injury\n",
      "Processing class: Paramedics\n",
      "Processing class: Person\n",
      "Processing class: Police\n",
      "Processing class: Road_block\n",
      "Processing class: Warning\n",
      "\n",
      "Successfully processed 2095 images.\n",
      "Features saved to: C:\\Users\\PC1\\OneDrive\\Desktop\\ders\\deeplearning\\project\\code\\Emergency-Icon-Classification-using-Deep-Learning\\features_dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the extracted images\n",
    "EXTRACTED_DATA_PATH = \"../data/extracted\"\n",
    "OUTPUT_FILENAME = \"features_dataset.json\"\n",
    "\n",
    "# Run the pipeline\n",
    "extractor = IconFeatureExtractor()\n",
    "extractor.process_dataset(EXTRACTED_DATA_PATH, OUTPUT_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
