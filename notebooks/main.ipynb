{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1abb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import ResNet50_Weights, ViT_B_16_Weights\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Enable inline plotting for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bebf32",
   "metadata": {},
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b44f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(results, model_name):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss/accuracy curves for Deep Learning models.\n",
    "    \"\"\"\n",
    "    train_loss = results['train_loss']\n",
    "    val_loss = results['val_loss']\n",
    "\n",
    "    train_acc = results['train_acc']\n",
    "    val_acc = results['val_acc']\n",
    "\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, label='Val Loss')\n",
    "    plt.title(f'{model_name} - Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Val Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.makedirs(\"plots\")\n",
    "\n",
    "    save_path = f\"plots/{model_name}_curves.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.close() # Close plot to save memory\n",
    "    # plt.show() # Uncomment if you want to see plots immediately in notebook\n",
    "\n",
    "def plot_mlp_loss_curve(mlp_model, model_name=\"MLP\"):\n",
    "    \"\"\"\n",
    "    Plots the loss curve for Scikit-Learn MLPClassifier.\n",
    "    \"\"\"\n",
    "    if not hasattr(mlp_model, 'loss_curve_'):\n",
    "        print(f\"Warning: {model_name} does not have a loss curve.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(mlp_model.loss_curve_, label='Training Loss')\n",
    "    plt.title(f'{model_name} - Training Loss Curve')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.makedirs(\"plots\")\n",
    "\n",
    "    save_path = f\"plots/{model_name}_loss_curve.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Plots confusion matrix for both DL and ML models.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.makedirs(\"plots\")\n",
    "    \n",
    "    save_path = f\"plots/{model_name}_conf_matrix.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75af2c",
   "metadata": {},
   "source": [
    "# data_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d0a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(data_dir, batch_size=32):\n",
    "    \"\"\"\n",
    "    Loads and splits the dataset. Returns the dataloaders\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"Data directory not found: {data_dir}\")\n",
    "\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    full_dataset = datasets.ImageFolder(\n",
    "                    root=data_dir,\n",
    "                    transform=data_transform\n",
    "                )\n",
    "\n",
    "    class_names = full_dataset.classes\n",
    "    print(f\"Classes found: {class_names}\")\n",
    "\n",
    "    total_count = len(full_dataset)\n",
    "    train_count = int(0.7 * total_count)\n",
    "    val_count = int(0.15 * total_count)\n",
    "    test_count = total_count - train_count - val_count\n",
    "\n",
    "    print(f\"Dataset Split: Train={train_count}, Val={val_count}, Test={test_count}\")\n",
    "\n",
    "    train_data, val_data, test_data = random_split(\n",
    "                                        full_dataset,\n",
    "                                        [train_count, val_count, test_count]\n",
    "                                    )\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db152d8",
   "metadata": {},
   "source": [
    "# model_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05be5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, num_classes, device):\n",
    "    \"\"\"\n",
    "    Gets the wanted model from torch and returns it\n",
    "    \"\"\"\n",
    "\n",
    "    if model_name == \"resnet50\":\n",
    "        weights = ResNet50_Weights.DEFAULT\n",
    "        model = models.resnet50(weights=weights)\n",
    "\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    elif model_name == \"vit_b_16\":\n",
    "        weights = ViT_B_16_Weights.DEFAULT\n",
    "        model = models.vit_b_16(weights=weights)\n",
    "\n",
    "        num_features = model.heads.head.in_features\n",
    "        model.heads.head = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        print(\"Error. Wrong model name\")\n",
    "        return None\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd486492",
   "metadata": {},
   "source": [
    "# engine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1828eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_preds += torch.sum(preds == labels.data)\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_acc = correct_preds.double() / total_preds\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            correct_preds += torch.sum(preds == labels.data)\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_preds\n",
    "    epoch_acc = correct_preds.double() / total_preds\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def test(model, dataloader, device, class_names):\n",
    "    \"\"\"Test the model and print classification report.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(classification_report(\n",
    "            all_labels,\n",
    "            all_preds,\n",
    "            target_names=class_names,\n",
    "            labels=np.arange(len(class_names))\n",
    "        ))\n",
    "\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba78369",
   "metadata": {},
   "source": [
    "# ML Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0004da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IconMLManager:\n",
    "    \"\"\"Does data loading and model training for icon features\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def features_to_vectors(dataset):\n",
    "        \"\"\"Flatten JSON structure into a matrix X and a label matrix y\"\"\"\n",
    "        _x = []\n",
    "        _y = []\n",
    "\n",
    "        for sample in dataset:\n",
    "            feature_vector = []\n",
    "\n",
    "            # process subdivisions\n",
    "            for sub in sample['subdivisions']:\n",
    "                feature_vector.extend([\n",
    "                    sub['perimeter'],\n",
    "                    sub['area'],\n",
    "                    sub['compactness'],\n",
    "                    sub['corners_count'],\n",
    "                    sub['sharp_corners_count']\n",
    "                ])\n",
    "                feature_vector.extend(sub['hu_moments'])\n",
    "                feature_vector.extend([\n",
    "                    sub['line_directions']['horizontal'],\n",
    "                    sub['line_directions']['vertical'],\n",
    "                    sub['line_directions']['diag1'],\n",
    "                    sub['line_directions']['diag2']\n",
    "                ])\n",
    "\n",
    "            # process global features\n",
    "            g = sample['global']\n",
    "            feature_vector.extend([\n",
    "                g['perimeter'],\n",
    "                g['area'],\n",
    "                g['compactness'],\n",
    "                g['corners_count'],\n",
    "                g['sharp_corners_count'],\n",
    "                g['ellipse_count'],\n",
    "                g['diagonal_length'],\n",
    "                g['diagonal_angle'],\n",
    "                g['convex_area']['convex_area'],\n",
    "                g['convex_area']['solidity'],\n",
    "                g['avg_centroidal_radius']\n",
    "            ])\n",
    "            feature_vector.extend(g['hu_moments'])\n",
    "            feature_vector.extend([\n",
    "                g['line_directions']['horizontal'],\n",
    "                g['line_directions']['vertical'],\n",
    "                g['line_directions']['diag1'],\n",
    "                g['line_directions']['diag2']\n",
    "            ])\n",
    "\n",
    "            _x.append(feature_vector)\n",
    "            _y.append(sample['label'])\n",
    "\n",
    "        return np.array(_x), np.array(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6e8d6",
   "metadata": {},
   "source": [
    "# ML Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3cc12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import json\n",
    "\n",
    "def train_ml(json_path_str):\n",
    "    \"\"\"Runs the SVM and MLP training using extracted features\"\"\"\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(\"STARTING TRADITIONAL ML PIPELINE (SVM & MLP)\")\n",
    "    print(f\"{'='*30}\")\n",
    "\n",
    "    json_path = Path(json_path_str)\n",
    "\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {json_path} not found. Ensure extracted features exist.\")\n",
    "        return\n",
    "\n",
    "    ml_manager = IconMLManager()\n",
    "    X, y_raw = ml_manager.features_to_vectors(raw_data)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "\n",
    "    print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features per sample.\")\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.30, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    print(f\"Split: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # --- SVM ---\n",
    "    print(\"\\n--- Training SVM ---\")\n",
    "    svm_model = SVC(kernel='rbf', C=10.0, gamma='scale', random_state=42)\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    val_pred_svm = svm_model.predict(X_val_scaled)\n",
    "    test_pred_svm = svm_model.predict(X_test_scaled)\n",
    "    print(f\"SVM Val Accuracy: {accuracy_score(y_val, val_pred_svm):.4f}\")\n",
    "    print(f\"SVM Test Accuracy: {accuracy_score(y_test, test_pred_svm):.4f}\")\n",
    "\n",
    "    # SVM Confusion Matrix \n",
    "    plot_confusion_matrix(y_test, test_pred_svm, le.classes_, \"SVM\")\n",
    "\n",
    "    # --- MLP ---\n",
    "    print(\"\\n --- Training MLP (Sklearn) ---\")\n",
    "    mlp_model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    test_pred_mlp = mlp_model.predict(X_test_scaled)\n",
    "    print(f\"MLP Test Accuracy: {accuracy_score(y_test, test_pred_mlp):.4f}\")\n",
    "\n",
    "    print(\"\\n --- MLP Detailed Report ----\")\n",
    "    print(classification_report(y_test, test_pred_mlp,\n",
    "                                target_names=le.classes_))\n",
    "    \n",
    "    # MLP Visualizations\n",
    "    plot_confusion_matrix(y_test, test_pred_mlp, le.classes_, \"MLP\")\n",
    "    plot_mlp_loss_curve(mlp_model, \"MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b02f0c9",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02d94e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda\n",
      "\n",
      "==============================\n",
      "STARTING TRADITIONAL ML PIPELINE (SVM & MLP)\n",
      "==============================\n",
      "Dataset: 2095 samples, 118 features per sample.\n",
      "Split: Train=1466, Val=314, Test=315\n",
      "\n",
      "--- Training SVM ---\n",
      "SVM Val Accuracy: 0.9490\n",
      "SVM Test Accuracy: 0.9714\n",
      "\n",
      " --- Training MLP (Sklearn) ---\n",
      "MLP Test Accuracy: 0.9111\n",
      "\n",
      " --- MLP Detailed Report ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bomb       0.94      0.77      0.85        22\n",
      "         Car       1.00      0.96      0.98        23\n",
      "    Casualty       0.82      0.82      0.82        22\n",
      " Electricity       0.92      1.00      0.96        23\n",
      "        Fire       0.79      0.96      0.86        23\n",
      "Fire_brigade       1.00      1.00      1.00        22\n",
      "       Flood       0.95      0.78      0.86        23\n",
      "         Gas       0.83      0.83      0.83        23\n",
      "      Injury       0.83      0.91      0.87        22\n",
      "  Paramedics       1.00      1.00      1.00        22\n",
      "      Person       0.92      1.00      0.96        22\n",
      "      Police       1.00      0.83      0.90        23\n",
      "  Road_block       0.84      0.95      0.89        22\n",
      "     Warning       1.00      0.96      0.98        23\n",
      "\n",
      "    accuracy                           0.91       315\n",
      "   macro avg       0.92      0.91      0.91       315\n",
      "weighted avg       0.92      0.91      0.91       315\n",
      "\n",
      "Classes found: ['Bomb', 'Car', 'Casualty', 'Electricity', 'Fire', 'Fire_brigade', 'Flood', 'Gas', 'Injury', 'Paramedics', 'Person', 'Police', 'Road_block', 'Warning', 'detection', 'duplicates']\n",
      "Dataset Split: Train=1772, Val=221, Test=222\n",
      "\n",
      "------------------------------\n",
      "NOW TRAINING resnet50\n",
      "\n",
      "------------------------------\n",
      "Epoch 1/10 | Train Loss: 1.3609 | Train Acc: 0.7449 | Val Loss: 0.1556 | Val Acc: 0.9457\n",
      "Epoch 2/10 | Train Loss: 0.0812 | Train Acc: 0.9763 | Val Loss: 0.0349 | Val Acc: 1.0000\n",
      "Epoch 3/10 | Train Loss: 0.0375 | Train Acc: 0.9904 | Val Loss: 0.0173 | Val Acc: 0.9955\n",
      "Epoch 4/10 | Train Loss: 0.0366 | Train Acc: 0.9893 | Val Loss: 0.0190 | Val Acc: 1.0000\n",
      "Epoch 5/10 | Train Loss: 0.0117 | Train Acc: 0.9977 | Val Loss: 0.0237 | Val Acc: 0.9955\n",
      "Epoch 6/10 | Train Loss: 0.0134 | Train Acc: 0.9960 | Val Loss: 0.0293 | Val Acc: 0.9955\n",
      "Epoch 7/10 | Train Loss: 0.0132 | Train Acc: 0.9955 | Val Loss: 0.0166 | Val Acc: 0.9955\n",
      "Epoch 8/10 | Train Loss: 0.0039 | Train Acc: 1.0000 | Val Loss: 0.0300 | Val Acc: 0.9955\n",
      "Epoch 9/10 | Train Loss: 0.0220 | Train Acc: 0.9927 | Val Loss: 0.0231 | Val Acc: 0.9955\n",
      "Epoch 10/10 | Train Loss: 0.0209 | Train Acc: 0.9966 | Val Loss: 0.0271 | Val Acc: 0.9955\n",
      "\n",
      "--- resnet50 TEST RESULTS ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bomb       1.00      1.00      1.00        15\n",
      "         Car       1.00      1.00      1.00        12\n",
      "    Casualty       1.00      1.00      1.00        14\n",
      " Electricity       1.00      1.00      1.00        17\n",
      "        Fire       1.00      1.00      1.00        16\n",
      "Fire_brigade       1.00      1.00      1.00        16\n",
      "       Flood       1.00      1.00      1.00        11\n",
      "         Gas       1.00      1.00      1.00        15\n",
      "      Injury       1.00      1.00      1.00         9\n",
      "  Paramedics       1.00      1.00      1.00        14\n",
      "      Person       1.00      1.00      1.00        17\n",
      "      Police       1.00      1.00      1.00        17\n",
      "  Road_block       1.00      1.00      1.00        16\n",
      "     Warning       1.00      1.00      1.00        20\n",
      "   detection       0.86      1.00      0.92         6\n",
      "  duplicates       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           1.00       222\n",
      "   macro avg       0.99      0.99      0.99       222\n",
      "weighted avg       1.00      1.00      1.00       222\n",
      "\n",
      "Model Saved\n",
      "\n",
      "------------------------------\n",
      "NOW TRAINING vit_b_16\n",
      "\n",
      "------------------------------\n",
      "Epoch 1/10 | Train Loss: 0.6970 | Train Acc: 0.8098 | Val Loss: 0.1296 | Val Acc: 0.9412\n",
      "Epoch 2/10 | Train Loss: 0.0761 | Train Acc: 0.9735 | Val Loss: 0.1763 | Val Acc: 0.9367\n",
      "Epoch 3/10 | Train Loss: 0.0658 | Train Acc: 0.9808 | Val Loss: 0.1023 | Val Acc: 0.9683\n",
      "Epoch 4/10 | Train Loss: 0.0763 | Train Acc: 0.9735 | Val Loss: 0.1252 | Val Acc: 0.9593\n",
      "Epoch 5/10 | Train Loss: 0.0204 | Train Acc: 0.9955 | Val Loss: 0.0939 | Val Acc: 0.9729\n",
      "Epoch 6/10 | Train Loss: 0.0534 | Train Acc: 0.9836 | Val Loss: 0.1383 | Val Acc: 0.9593\n",
      "Epoch 7/10 | Train Loss: 0.0448 | Train Acc: 0.9876 | Val Loss: 0.0348 | Val Acc: 0.9864\n",
      "Epoch 8/10 | Train Loss: 0.0090 | Train Acc: 0.9972 | Val Loss: 0.0339 | Val Acc: 0.9864\n",
      "Epoch 9/10 | Train Loss: 0.0062 | Train Acc: 0.9989 | Val Loss: 0.0140 | Val Acc: 0.9955\n",
      "Epoch 10/10 | Train Loss: 0.0012 | Train Acc: 1.0000 | Val Loss: 0.0119 | Val Acc: 1.0000\n",
      "\n",
      "--- vit_b_16 TEST RESULTS ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bomb       1.00      1.00      1.00        15\n",
      "         Car       1.00      1.00      1.00        12\n",
      "    Casualty       0.93      1.00      0.97        14\n",
      " Electricity       1.00      0.94      0.97        17\n",
      "        Fire       1.00      1.00      1.00        16\n",
      "Fire_brigade       1.00      1.00      1.00        16\n",
      "       Flood       1.00      1.00      1.00        11\n",
      "         Gas       1.00      1.00      1.00        15\n",
      "      Injury       1.00      1.00      1.00         9\n",
      "  Paramedics       0.93      0.93      0.93        14\n",
      "      Person       1.00      1.00      1.00        17\n",
      "      Police       1.00      1.00      1.00        17\n",
      "  Road_block       0.94      1.00      0.97        16\n",
      "     Warning       1.00      0.95      0.97        20\n",
      "   detection       1.00      1.00      1.00         6\n",
      "  duplicates       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.99       222\n",
      "   macro avg       0.99      0.99      0.99       222\n",
      "weighted avg       0.99      0.99      0.99       222\n",
      "\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# --- GLOBAL SETTINGS ---\n",
    "# Accessing data by going up one directory since notebook is in \"notebooks\"\n",
    "DATA_PATH = \"../data/extracted\"\n",
    "JSON_FEATURES_PATH = \"../features_dataset.json\" \n",
    "\n",
    "MODELS_DL = [\"resnet50\", \"vit_b_16\"]\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0001\n",
    "\n",
    "def main_pipeline():\n",
    "    print(f\"Working on {DEVICE}\")\n",
    "\n",
    "    # 1. TRADITIONAL ML PART\n",
    "\n",
    "    if Path(JSON_FEATURES_PATH).exists():\n",
    "        train_ml(JSON_FEATURES_PATH)\n",
    "    else:\n",
    "        print(f\"Warning: {JSON_FEATURES_PATH} not found. Skipping ML training.\")\n",
    "        print(\"Please run extraction.ipynb first to generate the JSON file.\")\n",
    "    \n",
    "    # 2. DEEP LEARNING PART\n",
    "\n",
    "    if not Path(DATA_PATH).exists():\n",
    "        print(f\"Error: {DATA_PATH} not found.\")\n",
    "        return\n",
    "\n",
    "    # Using create_dataloaders function defined in previous cells\n",
    "    train_loader, val_loader, test_loader, class_names = create_dataloaders(DATA_PATH, BATCH_SIZE)\n",
    "\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.makedirs(\"models\")\n",
    "\n",
    "    for model_name in MODELS_DL:\n",
    "        print(f\"\\n{'-'*30}\")\n",
    "        print(f\"NOW TRAINING {model_name}\")\n",
    "        print(f\"\\n{'-'*30}\")\n",
    "\n",
    "        # get_model function (from previous cells)\n",
    "        model = get_model(model_name, len(class_names), DEVICE)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        results = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"val_acc\": []\n",
    "        }\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            # train and validate functions (from previous cells)\n",
    "            train_loss, train_acc = train(model, train_loader, criterion, optimizer, DEVICE)\n",
    "            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "\n",
    "            # Tensor check and float conversion\n",
    "            t_acc = train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc\n",
    "            v_acc = val_acc.item() if isinstance(val_acc, torch.Tensor) else val_acc\n",
    "\n",
    "            results[\"train_loss\"].append(train_loss)\n",
    "            results[\"train_acc\"].append(t_acc)\n",
    "            results[\"val_loss\"].append(val_loss)\n",
    "            results[\"val_acc\"].append(v_acc)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "                f\"Train Loss: {train_loss:.4f} | \"\n",
    "                f\"Train Acc: {t_acc:.4f} | \"\n",
    "                f\"Val Loss: {val_loss:.4f} | \"\n",
    "                f\"Val Acc: {v_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\n--- {model_name} TEST RESULTS ---\")\n",
    "\n",
    "        # test function (from previous cells)\n",
    "        y_true, y_pred = test(model, test_loader, DEVICE, class_names)\n",
    "\n",
    "        # Visualization (using utils functions)\n",
    "        plot_curves(results, model_name)\n",
    "        plot_confusion_matrix(y_true, y_pred, class_names, model_name)\n",
    "\n",
    "        # Saving the Model\n",
    "        torch.save(model.state_dict(), f\"models/{model_name}_final.pth\")\n",
    "        print(\"Model Saved\")\n",
    "\n",
    "        # Memory cleanup\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
