{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd360ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb5788",
   "metadata": {},
   "source": [
    "# extract_squares.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7ec3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareDetector:\n",
    "    \"\"\"Class for detecting and processing squares in images.\"\"\"\n",
    "\n",
    "    THRESH = 10  # For edge detection\n",
    "    AREA_THRESHOLD = 8000  # Minimum area to consider\n",
    "    EXPECTED_COLS = 5\n",
    "    EXPECTED_ROWS = 7\n",
    "    EXPECTED_TOTAL = 35  # Expected number of icon squares\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_by_aspect_ratio(\n",
    "        squares: List[np.ndarray],\n",
    "        max_ratio: float = 2.0\n",
    "    ) -> List[np.ndarray]:\n",
    "        \"\"\"Filter out rectangles that are too long compared to their width.\"\"\"\n",
    "        filtered = []\n",
    "\n",
    "        for sq in squares:\n",
    "            _, _, w, h = cv2.boundingRect(sq)\n",
    "            aspect_ratio = max(w, h) / min(w, h)\n",
    "            if aspect_ratio <= max_ratio:\n",
    "                filtered.append(sq)\n",
    "        return filtered\n",
    "\n",
    "    @staticmethod\n",
    "    def find_squares(image: np.ndarray):\n",
    "        \"\"\"Find large blobs in the given image.\"\"\"\n",
    "        squares = []\n",
    "\n",
    "        # Search for squares\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        gray = cv2.Canny(gray, 0, 0)\n",
    "        gray = cv2.dilate(gray, None)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(\n",
    "            gray,\n",
    "            cv2.RETR_LIST,\n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "            )\n",
    "\n",
    "        # Testing each contour\n",
    "        for contour in contours:\n",
    "            # Skip small areas (noise)\n",
    "            area = abs(cv2.contourArea(contour))\n",
    "            if area < SquareDetector.AREA_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int32(box)\n",
    "\n",
    "            squares.append(box)\n",
    "\n",
    "        # Filter rectangles out\n",
    "        squares = SquareDetector.filter_by_aspect_ratio(squares)\n",
    "        return squares\n",
    "\n",
    "    @staticmethod\n",
    "    def row_map_by_area(\n",
    "        squares: List[np.ndarray]\n",
    "    ) -> Dict[int, List[Tuple]]:\n",
    "        \"\"\"Select 35 squares by area similarity, then group them into rows.\"\"\"\n",
    "        if len(squares) < SquareDetector.EXPECTED_TOTAL:\n",
    "            raise ValueError(\n",
    "                \"Not enough squares: expected at least \"\n",
    "                + f\"{SquareDetector.EXPECTED_TOTAL}, got {len(squares)}\"\n",
    "            )\n",
    "\n",
    "        # Selecting 35 squares by area similarity\n",
    "        rects = [(sq, cv2.boundingRect(sq)) for sq in squares]\n",
    "        areas = np.array([w * h for _, (_, _, w, h) in rects])\n",
    "\n",
    "        median_area = np.median(areas)\n",
    "        diffs = np.abs(areas - median_area)\n",
    "\n",
    "        selected_idx = np.argsort(diffs)[:SquareDetector.EXPECTED_TOTAL]\n",
    "        selected_rects = [rects[i][1] for i in selected_idx]\n",
    "\n",
    "        # Sort by y center (top to bottom)\n",
    "        selected_rects.sort(key=lambda r: r[1] + r[3] / 2)\n",
    "\n",
    "        # Make rows\n",
    "        grid: Dict[int, List[Tuple]] = {}\n",
    "\n",
    "        for row_idx in range(SquareDetector.EXPECTED_ROWS):\n",
    "            start = row_idx * SquareDetector.EXPECTED_COLS\n",
    "            end = start + SquareDetector.EXPECTED_COLS\n",
    "\n",
    "            row = selected_rects[start:end]\n",
    "\n",
    "            if len(row) != SquareDetector.EXPECTED_COLS:\n",
    "                raise RuntimeError(\n",
    "                    f\"Row {row_idx} has {len(row)} squares\" +\n",
    "                    f\"instead of {SquareDetector.EXPECTED_COLS}\"\n",
    "                )\n",
    "\n",
    "            grid[row_idx] = row\n",
    "\n",
    "        return grid\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_duplicates(\n",
    "            squares: List[np.ndarray],\n",
    "            tolerance: int = 30\n",
    "    ) -> List[np.ndarray]:\n",
    "        \"\"\"Remove overlapping or nearly identical squares.\"\"\"\n",
    "        keep = [True] * len(squares)\n",
    "\n",
    "        for i, sq1 in enumerate(squares):\n",
    "            if not keep[i]:\n",
    "                continue\n",
    "\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(sq1)\n",
    "            area1 = w1 * h1\n",
    "\n",
    "            for j in range(i + 1, len(squares)):\n",
    "                if not keep[j]:\n",
    "                    continue\n",
    "\n",
    "                x2, y2, w2, h2 = cv2.boundingRect(squares[j])\n",
    "                area2 = w2 * h2\n",
    "\n",
    "                # Check if squares are similar in position\n",
    "                is_similar = (\n",
    "                    abs(x1 - x2) < tolerance and\n",
    "                    abs(y1 - y2) < tolerance and\n",
    "                    abs((x1 + w1) - (x2 + w2)) < tolerance and\n",
    "                    abs((y1 + h1) - (y2 + h2)) < tolerance\n",
    "                )\n",
    "\n",
    "                if is_similar:\n",
    "                    # Keep the bigger one\n",
    "                    if area1 > area2:\n",
    "                        keep[j] = False\n",
    "                    else:\n",
    "                        keep[i] = False\n",
    "                        break\n",
    "\n",
    "        filtered = [sq for i, sq in enumerate(squares) if keep[i]]\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7d636",
   "metadata": {},
   "source": [
    "# process.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efefb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_square(\n",
    "    cropped_square: np.ndarray,\n",
    "    padding: int = 20,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect the drawing within a cropped square, zoom to its bounding box,\n",
    "    and return a binary image resized to the original dimensions.\n",
    "    \"\"\"\n",
    "    height, width = cropped_square.shape[:2]\n",
    "\n",
    "    gray = cv2.cvtColor(cropped_square, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Binarize for contour detection\n",
    "    # OTSU is used to automatically determine threshold value\n",
    "    _, binary = cv2.threshold(\n",
    "        gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    if not contours:\n",
    "        return binary # Return potentially empty binary if no contours\n",
    "\n",
    "    # Bounding box over contours\n",
    "    points = np.vstack(contours)\n",
    "    x_rect, y_rect, w, h = cv2.boundingRect(points)\n",
    "\n",
    "    # Expand bounding box with padding\n",
    "    x_start = max(0, x_rect - padding)\n",
    "    y_start = max(0, y_rect - padding)\n",
    "    x_end = min(width, x_rect + w + padding)\n",
    "    y_end = min(height, y_rect + h + padding)\n",
    "\n",
    "    # Crop and resize binary image\n",
    "    icon = binary[y_start:y_end, x_start:x_end]\n",
    "    \n",
    "    if icon.size == 0:\n",
    "        return binary\n",
    "\n",
    "    icon_resized = cv2.resize(\n",
    "                    icon,\n",
    "                    (width, height),\n",
    "                    interpolation=cv2.INTER_NEAREST\n",
    "                )\n",
    "    # Morphological dilatation + opening to clean noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    thickened = cv2.dilate(icon_resized, kernel, iterations=1)\n",
    "    clean_icon = cv2.morphologyEx(thickened, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # if too much is removed, return previous image\n",
    "    if cv2.countNonZero(clean_icon) < 0.8 * cv2.countNonZero(icon_resized):\n",
    "        return icon_resized\n",
    "\n",
    "    return clean_icon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e93bb",
   "metadata": {},
   "source": [
    "# label.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "762dd73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(\n",
    "    squares: Dict[int, List[Tuple]],\n",
    "    file_terrminology: str\n",
    ") -> Dict[str, List[Tuple]]:\n",
    "    \"\"\"Assign labels to grouped squares based on their Y-position order.\"\"\"\n",
    "    labels = []\n",
    "    if file_terrminology == \"00000\":\n",
    "        labels = [\n",
    "            'Warning',\n",
    "            'Bomb',\n",
    "            'Car',\n",
    "            'Casualty',\n",
    "            'Electricity',\n",
    "            'Fire',\n",
    "            'Fire_brigade'\n",
    "        ]\n",
    "    elif file_terrminology == \"00001\":\n",
    "        labels = [\n",
    "            'Gas',\n",
    "            'Injury',\n",
    "            'Paramedics',\n",
    "            'Person',\n",
    "            'Police',\n",
    "            'Road_block',\n",
    "            'Flood'\n",
    "        ]\n",
    "    else:\n",
    "        print(\"Error: Unknown file terrminology\")\n",
    "        return {}\n",
    "\n",
    "    # Sort groups by Y-coordinate (top to bottom)\n",
    "    sorted_grps = sorted(squares.items(), key=lambda item: item[0])\n",
    "\n",
    "    # Map labels to rectangle groups\n",
    "    labeled_squares = {}\n",
    "    for i, (_, rectangles) in enumerate(sorted_grps):\n",
    "        if i < len(labels):\n",
    "            labeled_squares[labels[i]] = rectangles\n",
    "        else:\n",
    "            print(f\"Warning: {len(sorted_grps)} groups, {len(labels)} labels\")\n",
    "            break\n",
    "\n",
    "    return labeled_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f398551",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddf90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terminology(filename: str) -> str:\n",
    "    \"\"\"Extract terminology code from filename.\"\"\"\n",
    "    if filename.startswith(\"00000\"):\n",
    "        return \"00000\"\n",
    "    elif filename.startswith(\"00001\"):\n",
    "        return \"00001\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def save_debug_squares_image(\n",
    "    image,\n",
    "    squares: list,\n",
    "    output_path: Path,\n",
    "    filename: str,\n",
    "    case: str\n",
    "):\n",
    "    \"\"\"Save an image with frames around detected squares.\"\"\"\n",
    "    debug_img = image.copy()\n",
    "\n",
    "    for sq in squares:\n",
    "        x, y, w, h = cv2.boundingRect(sq)\n",
    "        cv2.rectangle(\n",
    "            debug_img,\n",
    "            (x, y),\n",
    "            (x + w, y + h),\n",
    "            (0, 255, 0),\n",
    "            thickness=2\n",
    "        )\n",
    "\n",
    "    debug_path = output_path / case\n",
    "    debug_path.mkdir(parents=True, exist_ok=True)\n",
    "    debug_path = debug_path / f\"debug_{filename}\"\n",
    "    cv2.imwrite(str(debug_path), debug_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaeae45",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b248070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(source_directory_str: str, debug_mode: bool = False):\n",
    "    source_path = Path(source_directory_str)\n",
    "    extracted_path = source_path.parent / \"extracted\"\n",
    "    extracted_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Statistics\n",
    "    total_processed = 0\n",
    "    label_counters = {}  # Track counter for each label\n",
    "\n",
    "    # Process all PNG files in the source directory\n",
    "    png_files = sorted(list(source_path.glob(\"*.png\")))\n",
    "\n",
    "    if not png_files:\n",
    "        print(f\"No PNG files found in {source_path}\")\n",
    "        return\n",
    "\n",
    "    for file_path in png_files:\n",
    "        filename = file_path.name\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        # Extract terminology from filename\n",
    "        terminology = extract_terminology(filename)\n",
    "        if not terminology:\n",
    "            print(f\"Rejected {filename} - filename must start with '00000' or '00001'\")\n",
    "            continue\n",
    "\n",
    "        # Read image\n",
    "        img = cv2.imread(str(file_path))\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Detect all squares and filter by aspect ratio\n",
    "        squares = SquareDetector.find_squares(img)\n",
    "\n",
    "        if debug_mode:\n",
    "            print(f\"Detected {len(squares)} squares\")\n",
    "            save_debug_squares_image(\n",
    "                img, squares, extracted_path, filename, \"detection\"\n",
    "            )\n",
    "\n",
    "        # Remove duplicates\n",
    "        squares = SquareDetector.remove_duplicates(squares)\n",
    "        if debug_mode:\n",
    "            print(f\"{len(squares)} squares after removing duplicates\")\n",
    "            save_debug_squares_image(\n",
    "                img, squares, extracted_path, filename, \"duplicates\"\n",
    "            )\n",
    "\n",
    "        # Map squares to groups by Y-coordinate\n",
    "        try:\n",
    "            grouped_squares = SquareDetector.row_map_by_area(squares)\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {filename}: {e}\")\n",
    "            continue\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Skipping {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Assign labels to groups\n",
    "        labeled_squares = labelling(grouped_squares, terminology)\n",
    "\n",
    "        if not labeled_squares:\n",
    "            print(\"Failed to assign labels\")\n",
    "            continue\n",
    "\n",
    "        # Process each labeled group\n",
    "        squares_extracted = 0\n",
    "        for label, rectangles in labeled_squares.items():\n",
    "            # Create label folder if it doesn't exist\n",
    "            label_folder = extracted_path / label\n",
    "            label_folder.mkdir(exist_ok=True)\n",
    "\n",
    "            # Initialize counter for this label if needed\n",
    "            if label not in label_counters:\n",
    "                label_counters[label] = 0\n",
    "\n",
    "            # Save each square in the group\n",
    "            for rect in rectangles:\n",
    "                x, y, w, h = rect\n",
    "                # Crop with 10 pixel margin to avoid borders (adjusted from original code)\n",
    "                # Ensure we don't crop out of bounds\n",
    "                y_start = max(0, y+15)\n",
    "                y_end = min(img.shape[0], y+h-15)\n",
    "                x_start = max(0, x+20)\n",
    "                x_end = min(img.shape[1], x+w-20)\n",
    "                \n",
    "                cropped_square = img[y_start:y_end, x_start:x_end]\n",
    "                \n",
    "                if cropped_square.size == 0:\n",
    "                    continue\n",
    "                    \n",
    "                processed_square = process_square(cropped_square)\n",
    "\n",
    "                if cv2.countNonZero(processed_square) <= 600:\n",
    "                    # Skip empty images\n",
    "                    continue\n",
    "\n",
    "                # Generate filename with counter\n",
    "                counter = label_counters[label]\n",
    "                image_filename = f\"{label}_{counter:05d}.png\"\n",
    "                image_path = label_folder / image_filename\n",
    "\n",
    "                cv2.imwrite(str(image_path), processed_square)\n",
    "\n",
    "                label_counters[label] += 1\n",
    "                squares_extracted += 1\n",
    "\n",
    "        total_processed += 1\n",
    "        print(f\"Extracted {squares_extracted} squares\")\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROCESSING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total files processed: {total_processed}\")\n",
    "    print(\"\\nSquares extracted by label:\")\n",
    "    for label, count in sorted(label_counters.items()):\n",
    "        print(f\"  {label:20s}: {count:5d} squares\")\n",
    "\n",
    "    print(f\"\\nResults saved to: {extracted_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d682f",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b2c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target directory has been found: C:\\Users\\PC1\\OneDrive\\Desktop\\ders\\deeplearning\\project\\code\\Emergency-Icon-Classification-using-Deep-Learning\\data\\all\n",
      "Processing: 00000_1.png\n",
      "Detected 66 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_10.png\n",
      "Detected 74 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_11.png\n",
      "Detected 66 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_12.png\n",
      "Detected 66 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_13.png\n",
      "Detected 66 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_14.png\n",
      "Detected 66 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_15.png\n",
      "Detected 71 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_16.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_17.png\n",
      "Detected 73 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_18.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_19.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_2.png\n",
      "Detected 68 squares\n",
      "41 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_20.png\n",
      "Detected 66 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_21.png\n",
      "Detected 69 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_22.png\n",
      "Detected 72 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_23.png\n",
      "Detected 75 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_24.png\n",
      "Detected 72 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_25.png\n",
      "Detected 72 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_26.png\n",
      "Detected 71 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_27.png\n",
      "Detected 71 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_28.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_29.png\n",
      "Detected 65 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_3.png\n",
      "Detected 66 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_30.png\n",
      "Detected 68 squares\n",
      "37 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_4.png\n",
      "Detected 66 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_5.png\n",
      "Detected 66 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_6.png\n",
      "Detected 69 squares\n",
      "37 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_7.png\n",
      "Detected 70 squares\n",
      "37 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_8.png\n",
      "Detected 68 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00000_9.png\n",
      "Detected 68 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_1.png\n",
      "Detected 81 squares\n",
      "45 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_10.png\n",
      "Detected 75 squares\n",
      "40 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_11.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_12.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_13.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_14.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_15.png\n",
      "Detected 75 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_16.png\n",
      "Detected 70 squares\n",
      "37 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_17.png\n",
      "Detected 73 squares\n",
      "37 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_18.png\n",
      "Detected 67 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_19.png\n",
      "Detected 75 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_2.png\n",
      "Detected 75 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_20.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_21.png\n",
      "Detected 74 squares\n",
      "39 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_22.png\n",
      "Detected 76 squares\n",
      "41 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_23.png\n",
      "Detected 73 squares\n",
      "43 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_24.png\n",
      "Detected 77 squares\n",
      "39 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_25.png\n",
      "Detected 73 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_26.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_27.png\n",
      "Detected 71 squares\n",
      "36 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_28.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_29.png\n",
      "Detected 65 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 30 squares\n",
      "Processing: 00001_3.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_30.png\n",
      "Detected 75 squares\n",
      "39 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_4.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_5.png\n",
      "Detected 70 squares\n",
      "35 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_6.png\n",
      "Detected 74 squares\n",
      "39 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_7.png\n",
      "Detected 76 squares\n",
      "38 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_8.png\n",
      "Detected 80 squares\n",
      "42 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "Processing: 00001_9.png\n",
      "Detected 72 squares\n",
      "37 squares after removing duplicates\n",
      "Extracted 35 squares\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE!\n",
      "============================================================\n",
      "Total files processed: 60\n",
      "\n",
      "Squares extracted by label:\n",
      "  Bomb                :   150 squares\n",
      "  Car                 :   150 squares\n",
      "  Casualty            :   150 squares\n",
      "  Electricity         :   150 squares\n",
      "  Fire                :   150 squares\n",
      "  Fire_brigade        :   150 squares\n",
      "  Flood               :   150 squares\n",
      "  Gas                 :   150 squares\n",
      "  Injury              :   150 squares\n",
      "  Paramedics          :   145 squares\n",
      "  Person              :   150 squares\n",
      "  Police              :   150 squares\n",
      "  Road_block          :   150 squares\n",
      "  Warning             :   150 squares\n",
      "\n",
      "Results saved to: ..\\data\\extracted\n"
     ]
    }
   ],
   "source": [
    "SOURCE_DIRECTORY = \"../data/all\"\n",
    "\n",
    "DEBUG_MODE = True\n",
    "\n",
    "src_path = Path(SOURCE_DIRECTORY)\n",
    "\n",
    "if src_path.exists():\n",
    "    print(f\"Target directory has been found: {src_path.resolve()}\")\n",
    "    run_pipeline(str(src_path), DEBUG_MODE)\n",
    "\n",
    "else:\n",
    "    print(f\"Couldn't find the directory: {src_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
